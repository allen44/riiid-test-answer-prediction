{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature engineering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1NkraGuA-_JZLfqhZdK_H7DKizTBk_4bm",
      "authorship_tag": "ABX9TyMqrlbD0+Mqqpc42v/66cRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allen44/riiid-test-answer-prediction/blob/main/feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufFybMZt7Kop"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "P-QfUXVkYHV2",
        "outputId": "191eff42-f466-4d46-c385-0c62bb5280ad"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/riiid-test-answer-prediction/\n",
        "%pwd\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/riiid-test-answer-prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/riiid-test-answer-prediction'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3IiMc1xSrFW"
      },
      "source": [
        "# Make Train Test Splits upon import from csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5TsYvtHTKe4"
      },
      "source": [
        "Using our insights gained from the EDA, when can import the data from csv with an get right on to feature engineering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab6dq5DybA-C",
        "outputId": "4a606d1e-06bf-4c13-c0a3-126104613533"
      },
      "source": [
        "#Choose pickle, or csv\n",
        "# suffix = '.pkl.gzip'\n",
        "suffix = '.csv'\n",
        "\n",
        "pwd = '/content/drive/MyDrive/Colab Notebooks/riiid-test-answer-prediction'\n",
        "\n",
        "# #Define data paths\n",
        "lectures_path = f'{pwd}/data/raw/lectures{suffix}'\n",
        "questions_path = f'{pwd}/data/raw/questions{suffix}'\n",
        "train_path = f'{pwd}/data/raw/train{suffix}'\n",
        "\n",
        "X_train_path = f'{pwd}/data/intermediate/train_test_splits/X_train.csv'\n",
        "X_test_path = f'{pwd}/data/intermediate/train_test_splits/X_test.csv'\n",
        "y_train_path = f'{pwd}/data/intermediate/train_test_splits/y_train.csv'\n",
        "y_test_path = f'{pwd}/data/intermediate/train_test_splits/y_test.csv'\n",
        "\n",
        "lectures_path, questions_path, train_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Colab Notebooks/riiid-test-answer-prediction/data/raw/lectures.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/riiid-test-answer-prediction/data/raw/questions.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/riiid-test-answer-prediction/data/raw/train.csv')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H67-BE0I9wZy",
        "outputId": "df16797c-0878-456e-b0ec-6b92c06c5c5e"
      },
      "source": [
        "nrows = 1.25*1e6\n",
        "\n",
        "# Import data from csv\n",
        "X = pd.read_csv(train_path, nrows=nrows)\n",
        "y = X.pop('answered_correctly') \n",
        "\n",
        "\n",
        "# Make Train Test Splits and Preprocess each split\n",
        "start = timer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                    X, \n",
        "                                    y, \n",
        "                                    test_size=0.20, \n",
        "                                    random_state=42,\n",
        "                                    stratify=y)\n",
        "end = timer()\n",
        "print(f'{round(end - start)} seconds elapsed.')\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Make sure the shapes are right\n",
        "assert X_train.shape[0]==y_train.shape[0]\n",
        "assert X_test.shape[0]==y_test.shape[0]\n",
        "assert X_train.shape[1]==X_test.shape[1]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 seconds elapsed.\n",
            "(1000000, 9) (250000, 9) (1000000,) (250000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTk0uD_pa9zR",
        "outputId": "0299eb63-9f7c-4c28-8109-65a427c53d3a"
      },
      "source": [
        "nrows"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1250000.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4AUVTPfuTLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce8471b-8767-4b12-97cb-df8edbc1affc"
      },
      "source": [
        "# Export splits to csv file\n",
        "start = timer()\n",
        "\n",
        "X_train.to_csv(X_train_path)\n",
        "X_test.to_csv(X_test_path)\n",
        "y_train.to_csv(y_train_path)\n",
        "y_test.to_csv(y_test_path)\n",
        "\n",
        "del X_train\n",
        "del X_test\n",
        "del y_train\n",
        "del y_test\n",
        "\n",
        "end = timer()\n",
        "print(f'{round(end - start)} seconds elapsed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7 seconds elapsed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni7IClq5Lwbh"
      },
      "source": [
        "# Merge events metadata with events data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71p5rYznRoI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4875b6ef-fc8f-4571-ef6e-ca5ffc95db83"
      },
      "source": [
        "def read_metadata_from_csv(lectures_path, questions_path):\n",
        "  lectures=pd.DataFrame()\n",
        "  questions=pd.DataFrame()\n",
        "  \n",
        "  # Read lectures and set dtypes\n",
        "  lectures_dtypes = {\n",
        "  'lecture_id': 'int16',\n",
        "  'tag': 'string',\n",
        "  'part': 'category',\n",
        "  'type_of': 'category'\n",
        "  }\n",
        "  lectures = pd.read_csv(lectures_path,\n",
        "                        usecols=lectures_dtypes.keys(),\n",
        "                        dtype=lectures_dtypes,\n",
        "                        index_col='lecture_id')\n",
        "  \n",
        "  # Read questions and set dtypes\n",
        "  questions_dtypes = {\n",
        "  'question_id': 'int16',\n",
        "  'bundle_id': 'int16',\n",
        "  'correct_answer': 'int8',\n",
        "  'part': 'int8',\n",
        "  'tags': 'string'}\n",
        "  questions = pd.read_csv(questions_path,\n",
        "                          usecols=questions_dtypes.keys(),\n",
        "                          dtype=questions_dtypes,\n",
        "                          index_col='question_id')\n",
        "\n",
        "  return lectures, questions\n",
        "\n",
        "\n",
        "lectures, questions = read_metadata_from_csv(lectures_path, questions_path)\n",
        "\n",
        "lectures.shape, questions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((418, 3), (13523, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BreFHntFSGuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4985d0a9-dd5a-46d5-b164-e3d484031c42"
      },
      "source": [
        "def binarize_tags(lectures, questions):\n",
        "  from sklearn.preprocessing import MultiLabelBinarizer\n",
        "  import re\n",
        "\n",
        "  # Binarize question tags\n",
        "  questions['tags'] = questions['tags'].str.split()\n",
        "  questions.dropna(subset=['tags'], inplace=True)\n",
        "  mlb = MultiLabelBinarizer()\n",
        "  q_labels = pd.DataFrame(mlb.fit_transform(questions['tags']),\n",
        "                              columns=mlb.classes_, \n",
        "                              index=questions['tags'].dropna().index,\n",
        "                           dtype=bool)\n",
        "  # questions.drop(columns=['tags'], inplace=True)\n",
        "  questions = pd.concat([questions, q_labels], axis=1)\n",
        "\n",
        "  # Binarize lecture tags\n",
        "  l_labels = pd.DataFrame(mlb.transform(lectures['tag'].dropna()),\n",
        "                              columns=mlb.classes_, \n",
        "                              index=lectures['tag'].dropna().index,\n",
        "                           dtype=bool)\n",
        "  lectures = pd.concat([lectures, l_labels], axis=1)\n",
        "\n",
        "  # Drop the now old columns\n",
        "  questions.drop(columns=['tags'], inplace=True)\n",
        "  lectures.drop(columns=['tag'], inplace=True)\n",
        "\n",
        "  # Rename the new columns\n",
        "  for df in [questions, lectures]:\n",
        "    for col_name in list(df.columns):\n",
        "      if not re.search('^[a-zA-Z]', col_name):\n",
        "        df['tag_' + col_name] = df[col_name]\n",
        "        df.drop(columns=[col_name], inplace=True)\n",
        "\n",
        "  return lectures, questions\n",
        "\n",
        "lectures, questions = binarize_tags(lectures, questions)\n",
        "\n",
        "lectures.shape, questions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((418, 190), (13522, 191))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fzi4kehtsK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ade2f6e-2edf-497a-e9bd-5c6dfe6fcefd"
      },
      "source": [
        "def read_events_and_target(X_path, y_path, nrows=1000, is_test=False):\n",
        " # Read events and set dtypes\n",
        "  events_dtypes = {\n",
        "      'timestamp': 'int64',\n",
        "      'user_id': 'category',\n",
        "      'content_id': 'int16',\n",
        "      'content_type_id': 'int8',\n",
        "      'task_container_id': 'int16',\n",
        "      'user_answer': 'int8',\n",
        "      'prior_question_elapsed_time': 'float16',\n",
        "      'prior_question_had_explanation': 'int8'\n",
        "  }\n",
        "  events = pd.read_csv(X_path,\n",
        "                      usecols=events_dtypes.keys(),\n",
        "                      # dtype=events_dtypes,\n",
        "                      nrows=nrows)\n",
        "  \n",
        "  target_dtypes = {\n",
        "      'answered_correctly': 'int8',\n",
        "  }\n",
        "  target = pd.read_csv(y_path,\n",
        "                        usecols=target_dtypes.keys(),\n",
        "                        dtype=target_dtypes,\n",
        "                        nrows=nrows)\n",
        "  \n",
        "  Xy = target.join(events)\n",
        "  return Xy\n",
        "\n",
        "# Read a subset, nrows, of train.csv\n",
        "Xy = read_events_and_target(X_train_path, y_train_path, nrows=100000, is_test=False)\n",
        "  \n",
        "Xy.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_91gJhDx2uo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d8b002a-c98d-43e8-965e-18733f927a90"
      },
      "source": [
        "def parse_questions_and_lecture_events(Xy):\n",
        "\n",
        "  Xy_q = Xy.loc[Xy['content_type_id']==0,:].drop(columns=['content_type_id'])\n",
        "  Xy_l = Xy.loc[Xy['content_type_id']==1, ['timestamp',\t'user_id', 'content_id', 'task_container_id']]\n",
        "\n",
        "  return Xy_q, Xy_l\n",
        "\n",
        "Xy_q, Xy_l = parse_questions_and_lecture_events(Xy)\n",
        "Xy_q.shape, Xy_l.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((97973, 8), (2027, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msy2gD8n0s3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e2ef62-7847-45fc-894b-e1e4cc159659"
      },
      "source": [
        "def merge_question_events_with_their_metadeta(Xy_q, questions):\n",
        "  Xy_qq = Xy_q.merge(questions,\n",
        "             how='left',\n",
        "             left_on='content_id',\n",
        "             right_on='question_id', \n",
        "             )\n",
        "  # Keep the initial index\n",
        "  Xy_qq.index = Xy_q.index\n",
        "  return Xy_qq\n",
        "\n",
        "Xy_qq = merge_question_events_with_their_metadeta(Xy_q, questions)\n",
        "Xy_qq.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97973, 199)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxJZN8qX29gf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a6b354-10fb-481a-f654-e92a27314374"
      },
      "source": [
        "def merge_lecture_events_with_their_metadeta(Xy_l, lectures):\n",
        "  Xy_ll = Xy_l.merge(lectures,\n",
        "             how='left',\n",
        "             left_on='content_id',\n",
        "             right_on='lecture_id')\n",
        "  # Keep the initial index\n",
        "  Xy_ll.index = Xy_l.index\n",
        "  return Xy_ll\n",
        "\n",
        "Xy_ll = merge_lecture_events_with_their_metadeta(Xy_l, lectures)\n",
        "Xy_ll.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2027, 194)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xymnZgMTWIa"
      },
      "source": [
        "Feature Engineering\n",
        "====\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL1XHfPKMBpd"
      },
      "source": [
        "def add_col_agg_data_and_drop_original_col(df, col, drop=True):\n",
        "  last_idx_of_df = df.shape[1]\n",
        "\n",
        "  agg_data_df = df.groupby(col).agg(\n",
        "      {'answered_correctly': ['mean', 'count'],\n",
        "      'prior_question_elapsed_time': ['mean'],\n",
        "       'timestamp': ['mean']\n",
        "      })\n",
        "  \n",
        "  #Flatten multi-index columns, then merge\n",
        "  agg_data_df.columns = ['_'.join(col) for col in agg_data_df.columns.values]\n",
        "  df = df.merge(agg_data_df,\n",
        "                how='left', \n",
        "                on=col)\n",
        "  \n",
        "  # Rename new columns and add to df\n",
        "  new_cols = df.iloc[:, (last_idx_of_df):]\n",
        "  for new_col in new_cols.columns.values:\n",
        "    df[col + '_' + new_col] = df[new_col]\n",
        "    df = df.drop(columns=new_col)\n",
        "\n",
        "  #Rename count column\n",
        "  unfortunately_named_col = col+'_answered_correctly_count'\n",
        "  df[col+'_count'] =df[unfortunately_named_col]\n",
        "  df = df.drop(columns=unfortunately_named_col)\n",
        "  \n",
        "  if drop:\n",
        "    df = df.drop(columns=col)\n",
        "  \n",
        "  return df\n",
        "\n",
        "# Xy_2 = add_col_agg_data_and_drop_original_col(Xy_qq, 'content_id')\n",
        "# Xy_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c_YTtwITbVJ"
      },
      "source": [
        "def feature_eng(df):\n",
        "  df = add_col_agg_data_and_drop_original_col(df, 'content_id')\n",
        "  df = add_col_agg_data_and_drop_original_col(df, 'bundle_id')\n",
        "  df = add_col_agg_data_and_drop_original_col(df, 'task_container_id')\n",
        "  return df\n",
        "\n",
        "# Xy_2 = feature_eng(Xy_qq)\n",
        "# # Show the feature-engineered columns\n",
        "# Xy_2.iloc[:, Xy_qq.shape[1]-3:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNRIwcJ_vaFu"
      },
      "source": [
        "# Feature encoding and transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUC6ejAyc_Ad"
      },
      "source": [
        "def drop_na_and_unneeded_cols(df):\n",
        "  print(f'shape before dropping na: {df.shape}')\n",
        "  # Drop NA\n",
        "  df = df.dropna()\n",
        "  df = df.dropna(axis=1)\n",
        "  print(f'shape after dropping na: {df.shape}')\n",
        "\n",
        "  # Drop unneeded columns\n",
        "  df = df.drop(columns='user_id')\n",
        "  print(f'shape after dropping user_id: {df.shape}')\n",
        "  return df\n",
        "\n",
        "# temp = drop_na_and_unneeded_cols(Xy_qq_eng)\n",
        "# temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv0Bqpq7v7Yq"
      },
      "source": [
        "def seperate_cat_num_bool_and_y(Xy_qq_eng):\n",
        "  # Relabel categories\n",
        "  cat_cols_list = [\n",
        "                  #  'content_id',\n",
        "                  #  'task_container_id',\n",
        "                   'user_answer',\n",
        "                  #  'bundle_id',\n",
        "                   'correct_answer',\n",
        "                   'part'\n",
        "                   ]\n",
        "  # Xy_qq_eng['content_id'] = Xy_qq_eng['content_id'].astype('category')\n",
        "  # Xy_qq_eng['task_container_id'] = Xy_qq_eng['task_container_id'].astype('category')\n",
        "  # Xy_qq_eng['user_answer'] = Xy_qq_eng['user_answer'].astype('category')\n",
        "  # Xy_qq_eng['bundle_id'] = Xy_qq_eng['bundle_id'].astype('category')\n",
        "  # Xy_qq_eng['correct_answer'] = Xy_qq_eng['correct_answer'].astype('category')\n",
        "  # Xy_qq_eng['part'] = Xy_qq_eng['part'].astype('category')\n",
        "\n",
        "  # Seperate y\n",
        "  y = Xy_qq_eng['answered_correctly']\n",
        "  X = Xy_qq_eng.drop(columns='answered_correctly')\n",
        "\n",
        "  # Seperate the categorical and numerical variables\n",
        "  # X_cat = Xy_qq_eng.select_dtypes(['category'])\n",
        "  X_bool = X.select_dtypes(bool)\n",
        "  X = X.drop(columns=X_bool.columns)\n",
        "  X_cat = X.loc[:, cat_cols_list]\n",
        "  X = X.drop(columns=X_cat.columns)\n",
        "  X_num = X\n",
        "\n",
        "\n",
        "  #Save the column labels for later\n",
        "  X_cat_columns = X_cat.columns\n",
        "  X_num_columns = X_num.columns\n",
        "\n",
        "  assert X_cat.shape[1] + X_num.shape[1] + X_bool.shape[1] + 1 == Xy_qq_eng.shape[1]\n",
        "  assert X_cat.shape[0] == X_num.shape[0]\n",
        "  assert X_num.shape[0] == X_bool.shape[0]\n",
        "  assert X_bool.shape[0] == y.shape[0]\n",
        "  return X_cat, X_num, X_bool, y\n",
        "\n",
        "# X_cat, X_num, X_bool, y = seperate_cat_num_bool_and_y(temp)\n",
        "# X_cat.shape[1], X_num.shape[1], X_bool.shape[1], y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzJjG0OCwPjA"
      },
      "source": [
        "#One Hot encode the categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qrcUrFnDQDQ"
      },
      "source": [
        "def encode_cat_feautures(X_cat, fitted_onehot=None):\n",
        "  # Apply OneHotEncoder() on Dataframe\n",
        "  from sklearn.preprocessing import OneHotEncoder\n",
        "  # 1. INSTANTIATE\n",
        "  if fitted_onehot==None: # Train data\n",
        "    enc = OneHotEncoder(dtype=bool, handle_unknown='ignore')\n",
        "    # 2. FIT\n",
        "    enc.fit(X_cat)\n",
        "  else: # Test data\n",
        "    enc = fitted_onehot\n",
        "  # 3. Transform\n",
        "  X_cat_encoded = enc.transform(X_cat)\n",
        "  # # To dataframe\n",
        "  X_cat_encoded = pd.DataFrame.sparse.from_spmatrix(X_cat_encoded, \n",
        "                                                    index=X_cat.index, \n",
        "                                                    columns=enc.get_feature_names())\n",
        "  X_cat_encoded = X_cat_encoded.sparse.to_dense()\n",
        "  return X_cat_encoded, enc\n",
        "\n",
        "# X_cat_encoded, onehot = encode_cat_feautures(X_cat, fitted_onehot=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FES4nqoT5AJE"
      },
      "source": [
        "# Scale the numeric features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_Br5tZuzOG2"
      },
      "source": [
        "def encode_num_feautures(X_num, fitted_scaler=None):\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "  start = timer()\n",
        "  print('scaling')\n",
        "\n",
        "  # 1. INSTANTIATE\n",
        "  if fitted_scaler==None: # Train data\n",
        "    scaler = StandardScaler()\n",
        "    assert isinstance(scaler, StandardScaler)\n",
        "    # 2. FIT and transform\n",
        "    X_num_scaled = scaler.fit_transform(X_num)\n",
        "  else: # Test Data\n",
        "    assert isinstance(fitted_scaler, StandardScaler)\n",
        "    scaler = fitted_scaler\n",
        "    X_num_scaled = scaler.transform(X_num)\n",
        "  \n",
        "  end = timer()\n",
        "  print(f'{round(end - start)} seconds elapsed.')\n",
        "\n",
        "  # print(f'X_num_scaled mean: {X_num_scaled.mean()}')\n",
        "  # print(f'X_num_scaled std: {X_num_scaled.std()}')\n",
        "\n",
        "  # To dataframe\n",
        "  X_num_scaled = pd.DataFrame(X_num_scaled, \n",
        "                              index=X_num.index, \n",
        "                              columns=X_num.columns)\n",
        "  \n",
        "  return X_num_scaled, scaler\n",
        "\n",
        "\n",
        "# X_num_scaled, scaler = encode_num_feautures(X_num, fitted_scaler=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6g_hgHv6wNV"
      },
      "source": [
        "#  Recombine the features into one dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkXGCe5CzszU"
      },
      "source": [
        "def join_encoded_cat_and_scaled_num(X_cat_encoded_df, X_num_scaled_df, X_bool_df, debug=False):\n",
        "  # Join categorical and numerical features\n",
        "  X = X_num_scaled_df.join(X_cat_encoded_df.join(X_bool_df))\n",
        "\n",
        "  if debug==True:\n",
        "    print(\"\\njoin_encoded_cat_and_scaled_num():\")\n",
        "    print(f\"return X=\\n{X}\")\n",
        "    print(f\"X.shape= {X.shape}\\n\")\n",
        "\n",
        "  return X\n",
        "\n",
        "X = join_encoded_cat_and_scaled_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65LFwzzW2G89"
      },
      "source": [
        "# Preprocess the test data set using the same transformers as the training data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWk5keTn2OZR"
      },
      "source": [
        "def preprocess_data(X_path, y_path, train_cat_transformer=None, train_num_transformer=None, nrows=1000, is_test=False):\n",
        "  if is_test:\n",
        "    assert train_cat_transformer\n",
        "    assert train_num_transformer\n",
        "\n",
        "  lectures, questions = read_metadata_from_csv(lectures_path, questions_path)\n",
        "  lectures, questions = binarize_tags(lectures, questions)\n",
        "\n",
        "  Xy = read_events_and_target(X_path, y_path, nrows=nrows, is_test=is_test)\n",
        "\n",
        "  Xy_q, Xy_l = parse_questions_and_lecture_events(Xy)\n",
        "\n",
        "  Xy_qq = merge_question_events_with_their_metadeta(Xy_q, questions)\n",
        "  Xy_ll = merge_lecture_events_with_their_metadeta(Xy_l, lectures)\n",
        "\n",
        "  Xy_qq = feature_eng(Xy_qq)\n",
        "\n",
        "  Xy_qq_2 = drop_na_and_unneeded_cols(Xy_qq)\n",
        "\n",
        "  X_cat, X_num, X_bool, y = seperate_cat_num_bool_and_y(Xy_qq_2)\n",
        "\n",
        "  X_cat_encoded, onehot = encode_cat_feautures(X_cat, fitted_onehot=train_cat_transformer)\n",
        "  X_num_scaled, scaler = encode_num_feautures(X_num, fitted_scaler=train_num_transformer)\n",
        "  X = join_encoded_cat_and_scaled_num(X_cat_encoded, X_num_scaled, X_bool)\n",
        "\n",
        "  if is_test:\n",
        "    return X, y\n",
        "  else:\n",
        "    return X, y, onehot, scaler\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8ftkc92ptzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd33e7d1-8717-44e2-83fc-18c6fa09502b"
      },
      "source": [
        "%%time\n",
        "\n",
        "X_train, y_train, cat_enc, num_enc = preprocess_data(X_train_path, \n",
        "                                                     y_train_path, \n",
        "                                                     nrows=nrows, \n",
        "                                                     is_test=False)\n",
        "X_test, y_test = preprocess_data(X_test_path, \n",
        "                                 y_test_path, \n",
        "                                 cat_enc, \n",
        "                                 num_enc, \n",
        "                                 nrows=nrows, \n",
        "                                 is_test=True)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape before dropping na: (980138, 208)\n",
            "shape after dropping na: (976295, 208)\n",
            "shape after dropping user_id: (976295, 207)\n",
            "scaling\n",
            "2 seconds elapsed.\n",
            "shape before dropping na: (245035, 208)\n",
            "shape after dropping na: (244123, 208)\n",
            "shape after dropping user_id: (244123, 207)\n",
            "scaling\n",
            "0 seconds elapsed.\n",
            "CPU times: user 11.9 s, sys: 733 ms, total: 12.6 s\n",
            "Wall time: 12.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqtjp2zP1lck"
      },
      "source": [
        "# Save data as binary files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P55EPgKc7dFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8ec989-d6b7-40d6-e0a8-01ac9c0ad4e7"
      },
      "source": [
        "suffix = '.pkl.gzip'\n",
        "\n",
        "with open(f'{pwd}/data/intermediate/feature_engineered/X_train_{str(round(nrows))}{suffix}' , 'wb') as f:\n",
        "  X_train.to_pickle(f)\n",
        "  print(f'saved to {f}')\n",
        "with open(f'{pwd}/data/intermediate/feature_engineered/y_train_{str(round(nrows))}{suffix}', 'wb') as f:\n",
        "  y_train.to_pickle(f)\n",
        "  print(f'saved to {f}')\n",
        "with open(f'{pwd}/data/intermediate/feature_engineered/X_test_{str(round(nrows))}{suffix}' , 'wb') as f:\n",
        "  X_test.to_pickle(f)\n",
        "  print(f'saved to {f}')\n",
        "with open(f'{pwd}/data/intermediate/feature_engineered/y_test_{str(round(nrows))}{suffix}' , 'wb') as f:\n",
        "  y_test.to_pickle(f)\n",
        "  print(f'saved to {f}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved to <_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/riiid-test-answer-prediction/data/intermediate/feature_engineered/X_train_1250000.pkl.gzip'>\n",
            "saved to <_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/riiid-test-answer-prediction/data/intermediate/feature_engineered/y_train_1250000.pkl.gzip'>\n",
            "saved to <_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/riiid-test-answer-prediction/data/intermediate/feature_engineered/X_test_1250000.pkl.gzip'>\n",
            "saved to <_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/riiid-test-answer-prediction/data/intermediate/feature_engineered/y_test_1250000.pkl.gzip'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMO8Xa0gcG17"
      },
      "source": [
        "# Future work\n",
        "\n",
        "I could re-implement the transformation pipeline using sklearn Pipelines."
      ]
    }
  ]
}